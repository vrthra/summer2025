{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Earley* parsing algorithm was invented by Jay Earley in 1970. It\n",
    "can be used to parse strings that conform to a context-free grammar. The\n",
    "algorithm uses a chart for parsing -- that is, it is implemented as a dynamic\n",
    "program relying on solving simpler sub-problems.\n",
    "\n",
    "Earley parsers are very appealing for a practitioner because they can use any\n",
    "context-free grammar for parsing a string, and from the parse forest generated,\n",
    "one can recover all (even an infinite number) of parse trees that correspond to\n",
    "the given grammar.\n",
    "\n",
    "**Note.** This notebook does not implement the Leo optimization.\n",
    "A more detailed worked out notebook that explains and implements the Leo optimization can be seen [here](https://rahul.gopinath.org/post/2021/02/06/earley-parsing/) from which this notebook has been adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "```python\n",
    "import earleyparser as P\n",
    "my_grammar = {'<start>': [['1', '<A>'],\n",
    "                          ['2']\n",
    "                         ],\n",
    "              '<A>'    : [['a']]}\n",
    "my_parser = P.EarleyParser(my_grammar)\n",
    "for tree in my_parser.parse_on(text='1a', start_symbol='<start>'):\n",
    "    print(P.format_parsetree(tree))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, as per traditional implementations,\n",
    "there can only be one expansion rule for the `<start>` symbol. We work around\n",
    "this restriction by simply constructing as many charts as there are expansion\n",
    "rules, and returning all parse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = {\n",
    "    '<start>': [['<expr>']],\n",
    "    '<expr>': [\n",
    "        ['<term>', '+', '<expr>'],\n",
    "        ['<term>', '-', '<expr>'],\n",
    "        ['<term>']],\n",
    "    '<term>': [\n",
    "        ['<fact>', '*', '<term>'],\n",
    "        ['<fact>', '/', '<term>'],\n",
    "        ['<fact>']],\n",
    "    '<fact>': [\n",
    "        ['<digits>'],\n",
    "        ['(','<expr>',')']],\n",
    "    '<digits>': [\n",
    "        ['<digit>','<digits>'],\n",
    "        ['<digit>']],\n",
    "    '<digit>': [[\"%s\" % str(i)] for i in range(10)],\n",
    "}\n",
    "START = '<start>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another grammar that targets the same language. Unlike the first\n",
    "grammar, this grammar produces ambiguous parse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_grammar = {\n",
    "    '<start>': [['<expr>']],\n",
    "    '<expr>': [\n",
    "        ['<expr>', '+', '<expr>'],\n",
    "        ['<expr>', '-', '<expr>'],\n",
    "        ['<expr>', '*', '<expr>'],\n",
    "        ['<expr>', '/', '<expr>'],\n",
    "        ['(', '<expr>', ')'],\n",
    "        ['<integer>']],\n",
    "    '<integer>': [\n",
    "        ['<digits>']],\n",
    "    '<digits>': [\n",
    "        ['<digit>','<digits>'],\n",
    "        ['<digit>']],\n",
    "    '<digit>': [[\"%s\" % str(i)] for i in range(10)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "An Earley parser executes the following steps for parsing:\n",
    "\n",
    "Use `<start>` as the entry into parsing. At this point, we want to parse the\n",
    "given string by the nonterminal `<start>`. The _definition_ of `<start>`\n",
    "contains the possible expansion rule that can match the given string. Each\n",
    "expansion rule can be thought of as a *parsing path*, with contiguous\n",
    "substrings of the given input string matched by the particular terms in the\n",
    "rule.\n",
    "\n",
    "* When given a nonterminal to match the string, the essential idea is to\n",
    "  get the rules in the definition, and add them to the current set of\n",
    "  parsing paths to try with the given string. Within the parsing path, we have\n",
    "  a parsed index which denotes the progress of parsing that particular path\n",
    "  (i.e the point till which the string until now has been recognized by that\n",
    "  path, and any parents of this path). When a rule is newly added, this parsed\n",
    "  index is set to zero.\n",
    "\n",
    "* We next look at our set of possible parsing paths, and check if any of these\n",
    "  paths start with a nonterminal. If one is found, then for that parsing path to\n",
    "  be completed with the given string, that nonterminal has to be recognized\n",
    "  first. So, we add the expansion rules corresponding to that nonterminal to the\n",
    "  list of possible parsing paths. We do this recursively.\n",
    "\n",
    "* Now, examine the current letter in the input. Then select all parsing paths\n",
    "  that have that particular letter at the parsed index. These expressions can\n",
    "  now advance one step to the next index. We add such parsing paths to the\n",
    "  set of parsing paths to try for the next character.\n",
    "\n",
    "* While doing this, any parsing paths have finished parsing, fetch its\n",
    "  corresponding nonterminal and advance all parsing paths that have that\n",
    "  nonterminal at the parsing index.\n",
    "\n",
    "* Continue recursively until the parsing path corresponding to `<start>` has\n",
    "  finished.\n",
    "\n",
    "\n",
    "The chart parser depends on a chart (a table) for parsing. The columns\n",
    "correspond to the characters in the input string. Each column represents a set\n",
    "of *states*, and corresponds to the legal rules to follow from that point on.\n",
    "\n",
    "Say we start with the following grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_grammar = {\n",
    "    '<start>': [['<A>','<B>']],\n",
    "    '<A>': [['a', '<B>', 'c'], ['a', '<A>']],\n",
    "    '<B>': [['b', '<C>'], ['<D>']],\n",
    "    '<C>': [['c']],\n",
    "    '<D>': [['d']]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earley parser produces a table of possible parse paths at each letter index of\n",
    "the table. Given an input `adcd`, we seed the column `0`  with:\n",
    "\n",
    "```\n",
    "   <start>: | <A> <B>\n",
    "```\n",
    "\n",
    "where the `|` represents the parsing index (also called the dot). This indicates\n",
    "that we are at the starting, and the next step is to identify `<A>`. After this\n",
    "rule is processed, the column would contain two more states\n",
    "\n",
    "```\n",
    "   <A>: | a <B> <c>\n",
    "   <A>: | a <A>\n",
    "```\n",
    "which represents two parsing paths to complete `<A>`.\n",
    "\n",
    "After processing of column `0` (which corresponds to input character `a`), we\n",
    "would find the following in column `1` (which corresponds to the input character `b`)\n",
    "\n",
    "```\n",
    "   <A>: a | <B> c\n",
    "   <A>: a | <A>\n",
    "   <B>: | b <C>\n",
    "   <B>: | <D>\n",
    "   <A>: | a <B> c\n",
    "   <A>: | a <A>\n",
    "   <D>: | d\n",
    "```\n",
    "\n",
    "Similarly, the next column (column `2` corresponding to `d`) would contain the following.\n",
    "\n",
    "```\n",
    "   <D>: | d\n",
    "   <B>: <D> |\n",
    "   <A>: a <B> | c\n",
    "```\n",
    "\n",
    "Next, column `3` corresponding to `c` would contain:\n",
    "```\n",
    "   <A>: a <B> c |\n",
    "   <start>: <A> | <B>\n",
    "   <B>: | <b> <C>\n",
    "   <B>: | <D>\n",
    "   <D>: | d\n",
    "```\n",
    "\n",
    "Finally, column `4` (`d`) would contain this at the end of processing.\n",
    "```\n",
    "   <D>: d |\n",
    "   <B>: <D> |\n",
    "   <start>: <A> <B> |\n",
    "```\n",
    "\n",
    "This is how the table or the chart -- from where the parsing gets its name: chart parsing -- gets filled.\n",
    "\n",
    "## The Column Data Structure\n",
    "\n",
    "The column contains a set of states. Each column corresponds\n",
    "to a character (or a token if tokens are used).\n",
    "Note that the states in a column corresponds to the parsing expression that will\n",
    "occur once that character has been read. That is, the first column will\n",
    "correspond to the parsing expression when no characters have been read.\n",
    "\n",
    "The column allows for adding states, and checks to prevent duplication of\n",
    "states. Why do we need to prevent duplication? The problem is left recursion.\n",
    "We need to detect and curtail left recursion, which is indicated by non-unique\n",
    "states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column:\n",
    "    def __init__(self, index, letter):\n",
    "        self.index, self.letter = index, letter\n",
    "        self.states, self._unique = [], {}\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n",
    "            str(state) for state in self.states if state.finished()))\n",
    "\n",
    "    def to_repr(self):\n",
    "        return \"%s chart[%d]\\n%s\" % (self.letter, self.index, \"\\n\".join(\n",
    "            str(state) for state in self.states))\n",
    "\n",
    "    def add(self, state):\n",
    "        if state in self._unique:\n",
    "            return self._unique[state]\n",
    "        self._unique[state] = state\n",
    "        self.states.append(state)\n",
    "        state.e_col = self\n",
    "        return self._unique[state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The State Data Structure\n",
    "\n",
    "A state represents a parsing path (which corresponds to the nonterminal, and the\n",
    "expansion rule that is being followed) with the current parsed index. \n",
    "Each state contains the following:\n",
    "\n",
    "* name: The nonterminal that this rule represents.\n",
    "* expr: The rule that is being followed\n",
    "* dot:  The point till which parsing has happened in the rule.\n",
    "* s_col: The starting point for this rule.\n",
    "* e_col: The ending point for this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, name, expr, dot, s_col, e_col=None):\n",
    "        self.name, self.expr, self.dot = name, expr, dot\n",
    "        self.s_col, self.e_col = s_col, e_col\n",
    "\n",
    "    def finished(self):\n",
    "        return self.dot >= len(self.expr)\n",
    "\n",
    "    def at_dot(self):\n",
    "        return self.expr[self.dot] if self.dot < len(self.expr) else None\n",
    "\n",
    "    def __str__(self):\n",
    "        def idx(var):\n",
    "            return var.index if var else -1\n",
    "\n",
    "        return self.name + ':= ' + ' '.join([\n",
    "            str(p)\n",
    "            for p in [*self.expr[:self.dot], '|', *self.expr[self.dot:]]\n",
    "        ]) + \"(%d,%d)\" % (idx(self.s_col), idx(self.e_col))\n",
    "\n",
    "    def copy(self):\n",
    "        return State(self.name, self.expr, self.dot, self.s_col, self.e_col)\n",
    "\n",
    "    def _t(self):\n",
    "        return (self.name, self.expr, self.dot, self.s_col.index)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self._t())\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self._t() == other._t()\n",
    "\n",
    "    def advance(self):\n",
    "        return State(self.name, self.expr, self.dot + 1, self.s_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convenience methods `finished()`, `advance()` and `at_dot()` should be\n",
    "self explanatory. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    nt_name = '<B>'\n",
    "    nt_expr = tuple(sample_grammar[nt_name][1])\n",
    "    col_0 = Column(0, None)\n",
    "    a_state = State(nt_name, tuple(nt_expr), 0, col_0)\n",
    "    print(a_state.at_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, the next symbol to be parsed is `<D>`, and if we advance it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    b_state = a_state.advance()\n",
    "    print(b_state)\n",
    "    print(b_state.finished())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basic Parser Interface\n",
    "\n",
    "We start with a bare minimum interface for a parser. It should allow one\n",
    "to parse a given text using a given nonterminal (which should be present in\n",
    "the grammar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def recognize_on(self, text, start_symbol):\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def parse_on(self, text, start_symbol):\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize the Earley parser, which is a parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(Parser):\n",
    "    def __init__(self, grammar, log = False, parse_exceptions = True, **kwargs):\n",
    "        self._grammar = grammar\n",
    "        self.epsilon = nullable(grammar)\n",
    "        self.log = log\n",
    "        self.parse_exceptions = parse_exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonterminals Deriving Empty Strings\n",
    "\n",
    "Earley parser handles *nullable* nonterminals separately. A nullable\n",
    "nonterminal is a nonterminal that can derive an empty string. That is\n",
    "at least one of the expansion rules must derive an empty string. An\n",
    "expansion rule derives an empty string if *all* of the tokens can\n",
    "derive the empty string. This means no terminal symbols (assuming we\n",
    "do not have zero width terminal symbols), and all nonterminal symbols\n",
    "can derive empty string.\n",
    "\n",
    "In this implementation, we first initialize the list of first level\n",
    "nullable nonterminals that contain an empty expansion. That is, they\n",
    "directly derive the empty string.\n",
    "Next, we remove any expansion rule that contains a token as these\n",
    "expansion rules will not result in empty strings. Next, we start with\n",
    "our current list of nullable nonterminals, take one at a time, and\n",
    "remove them from the current expansion rules. If any expansion rule\n",
    "becomes empty, the corresponding nonterminal is added to the nullable\n",
    "nonterminal list. This continues until all nullable nonterminals\n",
    "are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nt(k):\n",
    "    return (k[0], k[-1]) == ('<', '>')\n",
    "\n",
    "def rem_terminals(g):\n",
    "    g_cur = {}\n",
    "    for k in g:\n",
    "        alts = []\n",
    "        for alt in g[k]:\n",
    "            ts = [t for t in alt if not is_nt(t)]\n",
    "            if not ts:\n",
    "                alts.append(alt)\n",
    "        if alts:\n",
    "            g_cur[k] = alts\n",
    "    return g_cur\n",
    "\n",
    "def nullable(g):\n",
    "    nullable_keys = {k for k in g if [] in g[k]}\n",
    "\n",
    "    unprocessed  = list(nullable_keys)\n",
    "\n",
    "    g_cur = rem_terminals(g)\n",
    "    while unprocessed:\n",
    "        nxt, *unprocessed = unprocessed\n",
    "        g_nxt = {}\n",
    "        for k in g_cur:\n",
    "            g_alts = []\n",
    "            for alt in g_cur[k]:\n",
    "                alt_ = [t for t in alt if t != nxt]\n",
    "                if not alt_:\n",
    "                    nullable_keys.add(k)\n",
    "                    unprocessed.append(k)\n",
    "                    break\n",
    "                else:\n",
    "                    g_alts.append(alt_)\n",
    "            if g_alts:\n",
    "                g_nxt[k] = g_alts\n",
    "        g_cur = g_nxt\n",
    "\n",
    "    return nullable_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    nullable_grammar = {\n",
    "        '<start>': [['<A>', '<B>']],\n",
    "        '<A>': [['a'], [], ['<C>']],\n",
    "        '<B>': [['b']],\n",
    "        '<C>': [['<A>'], ['<B>']]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(nullable(nullable_grammar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chart Parser\n",
    "\n",
    "Earley parser is a chart parser. That is, it relies on a table of solutions\n",
    "to smaller problems. This table is called a chart (hence the name of such parsers -- chart parsers).\n",
    "\n",
    "### The Chart Construction\n",
    "\n",
    "Here, we begin the chart construction by \n",
    "seeding the chart with columns representing the tokens or characters.\n",
    "Consider our example grammar again. The starting point is,\n",
    "```\n",
    "   <start>: | <A> <B>\n",
    "```\n",
    "We add this state to the `chart[0]` to start the parse. Note that the term\n",
    "after dot is `<A>`, which will need to be recursively inserted to the column.\n",
    "We will see how to do that later.\n",
    "\n",
    "*Note:* In traditional Earley parsing, the starting nonterminal always have\n",
    "a single expansion rule. However, in many cases, you want to parse a fragment\n",
    "and this rule makes it cumbersome to use Earley parsing. Hence, we have\n",
    "opted to allow any nonterminal to be used as the starting nonterminal\n",
    "irrespective of whether it has a single rule or not.\n",
    "Interestingly, this does not have an impact on the parsing itself, but in\n",
    "the extraction of results.\n",
    "In essence, we seed *all* expansion rules into of the current start symbol\n",
    "to the chart at `column 0`. We will take care of that difference while\n",
    "building parse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def chart_parse(self, tokens, start, alts):\n",
    "        chart = [self.create_column(i, tok) for i, tok in enumerate([None, *tokens])]\n",
    "        for alt in alts:\n",
    "            chart[0].add(self.create_state(start, tuple(alt), 0, chart[0]))\n",
    "        return self.fill_chart(chart)\n",
    "\n",
    "    def create_column(self, i, tok): return Column(i, tok)\n",
    "\n",
    "    def create_state(self, sym, alt, num, col): return State(sym, alt, num, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seed our initial state in the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    v = ep.chart_parse(list('a'), START, sample_grammar[START])\n",
    "    print(v[0].states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we complete the chart. The idea here is to process one character or one\n",
    "element at a time. At each character, we examine the current parse paths\n",
    "(states) and continue forward any parse path that successfully parses the\n",
    "letter. We process any state that is present in the current column in the\n",
    "following fashion.\n",
    "\n",
    "There are three main methods we use: `predict()`, `scan()`, and `complete()`\n",
    "\n",
    "\n",
    "#### Predict\n",
    "\n",
    "If in the current state, the term after the dot is a nonterminal, `predict()` is called. It\n",
    "adds the expansion of the nonterminal to the current column.\n",
    "\n",
    "If the term is nullable, then we simply advance the current state, and\n",
    "add that to the current column. This fix to the original Earley parsing\n",
    "was suggested by Aycock et al.[^aycock2002practical]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def predict(self, col, sym, state):\n",
    "        for alt in self._grammar[sym]:\n",
    "            col.add(self.create_state(sym, tuple(alt), 0, col))\n",
    "        if sym in self.epsilon:\n",
    "            col.add(state.advance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look our example, we have seeded the first column with `| <A> <B>`. Now,\n",
    "`fill_chart()` will find that the next term is `<A>` and call `predict()`\n",
    "which will then add the expansions of `<A>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    chart = ep.chart_parse(list('a'), START, sample_grammar[START])\n",
    "\n",
    "    for s in chart[0].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep.predict(chart[0], '<A>', s)\n",
    "    for s in chart[0].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the two rules of `<A>` has been added to\n",
    "the current column.\n",
    "\n",
    "#### Scan\n",
    "\n",
    "The `scan()` method is called if the next symbol in the current state is a terminal symbol. If the\n",
    "state matches the next term, moves the dot one position, and adds the new\n",
    "state to the column.\n",
    "\n",
    "For example, consider this state.\n",
    "```\n",
    "   <B>: | b c\n",
    "```\n",
    "If we scan the next column's letter, and that letter is `b`, then it matches the\n",
    "next symbol. So, we can advance the state by one symbol, and add it to the next\n",
    "column.\n",
    "```\n",
    "   <B>: b | c\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def scan(self, col, state, letter):\n",
    "        if letter == col.letter:\n",
    "            col.add(state.advance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our continuing example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    chart = ep.chart_parse(list('a'), START, sample_grammar[START])\n",
    "    ep.predict(chart[0], '<A>', s)\n",
    "\n",
    "    new_state = chart[0].states[1]\n",
    "    print(new_state)\n",
    "\n",
    "    ep.scan(chart[1], new_state, 'a')\n",
    "    for s in chart[1].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `state[1]` in `chart[0]` that was waiting for `a` has\n",
    "advanced one letter after consuming `a`, and has been added to `chart[1]`.\n",
    "\n",
    "#### Complete\n",
    "\n",
    "The `complete()` method is called if a particular state has finished the rule\n",
    "during execution. It first extracts the start column of the finished state, then\n",
    "for all states in the start column that is not finished, find the states that\n",
    "were parsing this current state (that is, we can go back to continue to parse\n",
    "those rules now). Next, shift them by one position, and add them to the current\n",
    "column.\n",
    "\n",
    "For example, say the state we have is:\n",
    "```\n",
    "   <A>: a | <B> c\n",
    "   <B>: b c |\n",
    "```\n",
    "The state `<B> b c |` is complete, and we need to advance any state that\n",
    "has `<B>` at the dot to one index forward, which is `<A>: a <B> | c`\n",
    "\n",
    "How do we determine the parent states? During predict, we added the predicted\n",
    "child states to the same column as that of the inspected state. So, the states\n",
    "will be found in the starting column of the current state, with the same symbol\n",
    "at_dot as that of the name of the completed state.\n",
    "\n",
    "We advance all such parents (producing new states) and add the new states to the\n",
    "current column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def complete(self, col, state):\n",
    "        parent_states = [st for st in state.s_col.states\n",
    "                 if st.at_dot() == state.name]\n",
    "        for st in parent_states:\n",
    "            col.add(st.advance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our example. We start parsing `ad`. So, we have three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    ep.fill_chart = lambda s: s\n",
    "\n",
    "    chart = ep.chart_parse(list('ad'), START, sample_grammar[START])\n",
    "    ep.predict(chart[0], '<A>', s)\n",
    "    for s in chart[0].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we populate column 1 which corresponds to letter `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(chart[1].letter)\n",
    "    for state in chart[0].states:\n",
    "        if state.at_dot() not in sample_grammar:\n",
    "            ep.scan(chart[1], state, 'a')\n",
    "    for s in chart[1].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the two states are waiting on `<A>` and `<B>`\n",
    "respectively at `at_dot()`.\n",
    "Hence, we run predict again to add the corresponding rules of `<A>` and `<B>`\n",
    "to the current column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    for state in chart[1].states:\n",
    "        if state.at_dot() in sample_grammar:\n",
    "            ep.predict(chart[1], state.at_dot(), state)\n",
    "    for s in chart[1].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have a list of states that are waiting\n",
    "for `b`, `a` and `d`.\n",
    "\n",
    "Our next letter is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(chart[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scan to populate `column 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    for state in chart[1].states:\n",
    "        if state.at_dot() not in sample_grammar:\n",
    "            ep.scan(chart[2], state, state.at_dot())\n",
    "\n",
    "    for s in chart[2].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, only `<D>` could advance to the next column (`chart[2]`)\n",
    "after reading `d`\n",
    "\n",
    "Finally, we use complete, so that we can advance the parents of the `<D>` state above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    for state in chart[2].states:\n",
    "        if state.finished():\n",
    "            ep.complete(chart[2], state)\n",
    "\n",
    "    for s in chart[2].states:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, that led to `<B>` being complete, and since `<B>` is\n",
    "complete, `<A>` also becomes complete.\n",
    "\n",
    "### Filling The Chart\n",
    "\n",
    "In the below algorithm, whenever the `at_dot()` is at a nonterminal\n",
    "symbol, the expansion rules of that nonterminal are added to the current\n",
    "rule (`predict()`) since each rule represents one valid parsing path. If on the\n",
    "other hand, `at_dot()` indicates processing finished for that nonterminal, we\n",
    "lookup the parent symbols and advance their parsing state (`complete()`). If we\n",
    "find that we are at a terminal symbol, we simply check if the current state can\n",
    "advance to parsing the next character (`scan()`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def fill_chart(self, chart):\n",
    "        for i, col in enumerate(chart):\n",
    "            for state in col.states:\n",
    "                if state.finished():\n",
    "                    self.complete(col, state)\n",
    "                else:\n",
    "                    sym = state.at_dot()\n",
    "                    if sym in self._grammar:\n",
    "                        self.predict(col, sym, state)\n",
    "                    else:\n",
    "                        if i + 1 >= len(chart):\n",
    "                            continue\n",
    "                        self.scan(chart[i + 1], state, sym)\n",
    "            if self.log: print(col.to_repr(), '\\n')\n",
    "        return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now recognize the given string as part of the language represented by the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar, log=True)\n",
    "    columns = ep.chart_parse('adcd', START, sample_grammar[START])\n",
    "    for c in columns: print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart above only shows completed entries. The parenthesized expression\n",
    "indicates the column just before the first character was recognized, and the\n",
    "ending column.\n",
    "\n",
    "Notice how the `<start>` nonterminal shows the dot at the end. That is, fully parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    last_col = columns[-1]\n",
    "    for s in last_col.states:\n",
    "        if s.name == '<start>':\n",
    "            print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation trees\n",
    "\n",
    "We use the following procedures to translate the parse forest to individual\n",
    "trees.\n",
    "\n",
    "### parse_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def parse_prefix(self, text, start_symbol):\n",
    "        alts = [tuple(alt) for alt in self._grammar[start_symbol]]\n",
    "        self.table = self.chart_parse(text, start_symbol, alts)\n",
    "        for col in reversed(self.table):\n",
    "            states = [st for st in col.states\n",
    "                if st.name == start_symbol and st.expr in alts and st.s_col.index == 0\n",
    "            ]\n",
    "            if states:\n",
    "                return col.index, states\n",
    "        return -1, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    cursor, last_states = ep.parse_prefix('adcd', START)\n",
    "    print(cursor, [str(s) for s in last_states])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse_on\n",
    "\n",
    "Our `parse_on()` method is slightly different from usual Earley implementations\n",
    "in that we accept any nonterminal symbol, not just nonterminal symbols with a\n",
    "single expansion rule. We accomplish this by computing a different chart for\n",
    "each expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def parse_on(self, text, start_symbol):\n",
    "        starts = self.recognize_on(text, start_symbol)\n",
    "        forest = self.parse_forest(self.table, starts)\n",
    "        for tree in self.extract_trees(forest):\n",
    "            yield tree\n",
    "\n",
    "    def recognize_on(self, text, start_symbol):\n",
    "        cursor, states = self.parse_prefix(text, start_symbol)\n",
    "        starts = [s for s in states if s.finished()]\n",
    "\n",
    "        if self.parse_exceptions:\n",
    "            if cursor < len(text) or not starts:\n",
    "                raise SyntaxError(\"at \" + repr(text[cursor:]))\n",
    "        return starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse_paths\n",
    "\n",
    "\n",
    "The parse_paths() method tries to unify the given expression in `named_expr` with\n",
    "the parsed string. For that, it extracts the last symbol in `named_expr` and\n",
    "checks if it is a terminal symbol. If it is, then it checks the chart at `til` to\n",
    "see if the letter corresponding to the position matches the terminal symbol.\n",
    "If it does, extend our start index by the length of the symbol.\n",
    "\n",
    "If the symbol was a nonterminal symbol, then we retrieve the parsed states\n",
    "at the current end column index (`til`) that correspond to the nonterminal\n",
    "symbol, and collect the start index. These are the end column indexes for\n",
    "the remaining expression.\n",
    "\n",
    "Given our list of start indexes, we obtain the parse paths from the remaining\n",
    "expression. If we can obtain any, then we return the parse paths. If not, we\n",
    "return an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def parse_paths(self, named_expr, chart, frm, til):\n",
    "        def paths(state, start, k, e):\n",
    "            if not e:\n",
    "                return [[(state, k)]] if start == frm else []\n",
    "            else:\n",
    "                return [[(state, k)] + r\n",
    "                        for r in self.parse_paths(e, chart, frm, start)]\n",
    "\n",
    "        *expr, var = named_expr\n",
    "        starts = None\n",
    "        if var not in self._grammar:\n",
    "            starts = ([(var, til - len(var),\n",
    "                        't')] if til > 0 and chart[til].letter == var else [])\n",
    "        else:\n",
    "            starts = [(s, s.s_col.index, 'n') for s in chart[til].states\n",
    "                      if s.finished() and s.name == var]\n",
    "\n",
    "        return [p for s, start, k in starts for p in paths(s, start, k, expr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(sample_grammar[START])\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    completed_start = last_states[0]\n",
    "    paths = ep.parse_paths(completed_start.expr, columns, 0, 4)\n",
    "    for path in paths:\n",
    "        print([list(str(s_) for s_ in s) for s in path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, the parse path for `<start>` given the input `adcd` included\n",
    "recognizing the expression `<A><B>`. This was recognized by the two states:\n",
    "`<A>` from input(0) to input(2) which further involved recognizing the rule\n",
    "`a<B>c`, and the next state `<B>` from input(3) which involved recognizing the\n",
    "rule `<D>`.\n",
    "\n",
    "### parse_forest\n",
    "\n",
    "The `parse_forest()` method takes the states which represents completed\n",
    "parses, and determines the possible ways that its expressions corresponded to\n",
    "the parsed expression. As we noted, it is here that we take care of multiple\n",
    "expansion rules for start symbol. (The `_parse_forest()` accepts a single\n",
    "state, and is the main driver that corresponds to traditional implementation,)\n",
    "For example, say we are parsing `1+2+3`, and the\n",
    "state has `[<expr>,+,<expr>]` in `expr`. It could have been parsed as either\n",
    "`[{<expr>:1+2},+,{<expr>:3}]` or `[{<expr>:1},+,{<expr>:2+3}]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def forest(self, s, kind, chart):\n",
    "        return self.parse_forest(chart, [s]) if kind == 'n' else (s, [])\n",
    "\n",
    "    def _parse_forest(self, chart, state):\n",
    "        pathexprs = self.parse_paths(state.expr, chart, state.s_col.index,\n",
    "                                     state.e_col.index) if state.expr else []\n",
    "        return (state.name, [[(v, k, chart) for v, k in reversed(pathexpr)]\n",
    "                            for pathexpr in pathexprs])\n",
    "\n",
    "    def parse_forest(self, chart, states):\n",
    "        names = list({s.name for s in states})\n",
    "        assert len(names) == 1\n",
    "        forest = [self._parse_forest(chart, state) for state in states]\n",
    "        return (names[0], [e for name, expr in forest for e in expr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ep = EarleyParser(sample_grammar)\n",
    "    result = ep.parse_forest(columns, last_states)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_trees\n",
    "\n",
    "We show how to extract a single tree first, and then generalize it to\n",
    "all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser(EarleyParser):\n",
    "    def extract_a_tree(self, forest_node):\n",
    "        name, paths = forest_node\n",
    "        if not paths:\n",
    "            return (name, [])\n",
    "        return (name, [self.extract_a_tree(self.forest(*p)) for p in paths[0]])\n",
    "\n",
    "    def extract_trees(self, forest):\n",
    "        yield self.extract_a_tree(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import src.utils as utils\n",
    "    mystring = '1+2+4'\n",
    "    parser = EarleyParser(a_grammar)\n",
    "    for tree in parser.parse_on(mystring, START):\n",
    "        utils.display_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiguous Parsing\n",
    "\n",
    "Ambiguous grammars can produce multiple derivation trees for some given string.\n",
    "In the above example, the `a_grammar` can parse `1+2+4` in as either `[1+2]+4` or `1+[2+4]`.\n",
    "\n",
    "That is, we need to extract all derivation trees.\n",
    "We enhance our `extract_trees()` as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as I\n",
    "\n",
    "class EarleyParser(EarleyParser):\n",
    "    def extract_trees(self, forest_node):\n",
    "        name, paths = forest_node\n",
    "        if not paths:\n",
    "            yield (name, [])\n",
    "        results = []\n",
    "        for path in paths:\n",
    "            ptrees = [self.extract_trees(self.forest(*p)) for p in path]\n",
    "            for p in I.product(*ptrees):\n",
    "                yield (name, p)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Using the same example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    mystring = '1+2+4'\n",
    "    parser = EarleyParser(a_grammar)\n",
    "    for tree in parser.parse_on(mystring, START):\n",
    "        utils.display_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.x0_1_Grammars as grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    v = '+16.18*-+4.4/5'\n",
    "    ep = EarleyParser(grammars.EXPR_GRAMMAR)\n",
    "    for t in ep.parse_on(v, grammars.EXPR_START):\n",
    "        utils.display_tree(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
